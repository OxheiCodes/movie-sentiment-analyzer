{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4ddb83-423e-430f-95a1-31b7b0462079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c8639-a590-455b-9fa1-868954397019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load IMDb dataset\n",
    "print(\"Loading IMDb dataset...\")\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# Use smaller subset for faster training (remove this for full dataset)\n",
    "train_data = dataset['train'].shuffle(seed=42).select(range(5000))\n",
    "test_data = dataset['test'].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36129891-fa9e-49c1-bf5a-b78081e387df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Convert to pandas DataFrames\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample reviews:\")\n",
    "print(train_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed47660a-c056-45aa-ac78-7d986fc8b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Text preprocessing function\n",
    "import re\n",
    "from html import unescape\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and preprocess text reviews\"\"\"\n",
    "    # Remove HTML entities\n",
    "    text = unescape(text)\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "print(\"\\nPreprocessing text...\")\n",
    "train_df['clean_text'] = train_df['text'].apply(preprocess_text)\n",
    "test_df['clean_text'] = test_df['text'].apply(preprocess_text)\n",
    "\n",
    "print(\"✅ Preprocessing complete\")\n",
    "print(\"\\nBefore preprocessing:\")\n",
    "print(train_df['text'].iloc[0][:200])\n",
    "print(\"\\nAfter preprocessing:\")\n",
    "print(train_df['clean_text'].iloc[0][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab119f0-040e-4510-85d9-0cb67a89fbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Prepare features and labels\n",
    "X_train = train_df['clean_text']\n",
    "y_train = train_df['label']\n",
    "X_test = test_df['clean_text']\n",
    "y_test = test_df['label']\n",
    "\n",
    "print(f\"\\n✅ Data split complete\")\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5facd051-812a-49bf-8d86-ff515be5d27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: TF-IDF Vectorization\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"BASELINE MODEL: Logistic Regression with TF-IDF\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create TF-IDF features\n",
    "print(\"\\nCreating TF-IDF features...\")\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), min_df=2)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(f\"✅ TF-IDF matrix shape: {X_train_tfidf.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce922bd-a7ea-4208-900a-6b6032db1057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Train Logistic Regression\n",
    "print(\"\\nTraining Logistic Regression model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"✅ Training completed in {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c499768c-1374-411e-b270-d1b7b14046b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Evaluate Logistic Regression\n",
    "print(\"\\n--- Logistic Regression Evaluation ---\")\n",
    "\n",
    "# Make predictions\n",
    "start_time = time.time()\n",
    "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
    "prediction_time = (time.time() - start_time) / len(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "precision_lr = precision_score(y_test, y_pred_lr)\n",
    "recall_lr = recall_score(y_test, y_pred_lr)\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"\\nAccuracy:  {accuracy_lr:.4f} ({accuracy_lr*100:.2f}%)\")\n",
    "print(f\"Precision: {precision_lr:.4f}\")\n",
    "print(f\"Recall:    {recall_lr:.4f}\")\n",
    "print(f\"F1 Score:  {f1_lr:.4f}\")\n",
    "print(f\"Avg prediction time: {prediction_time*1000:.2f}ms\")\n",
    "\n",
    "print(\"\\n\" + classification_report(y_test, y_pred_lr, target_names=['Negative', 'Positive']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969d12a2-a9f4-4438-a22d-9800a214c56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Confusion Matrix\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.title('Logistic Regression - Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/lr_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"✅ Confusion matrix saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7feffb8-01f5-4f93-8384-231f33b09257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Train Naive Bayes\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"COMPARISON MODEL: Naive Bayes\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nTraining Naive Bayes model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"✅ Training completed in {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6245488-5121-4b2a-8531-83aad007b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Evaluate Naive Bayes\n",
    "print(\"\\n--- Naive Bayes Evaluation ---\")\n",
    "\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "precision_nb = precision_score(y_test, y_pred_nb)\n",
    "recall_nb = recall_score(y_test, y_pred_nb)\n",
    "f1_nb = f1_score(y_test, y_pred_nb)\n",
    "\n",
    "print(f\"\\nAccuracy:  {accuracy_nb:.4f} ({accuracy_nb*100:.2f}%)\")\n",
    "print(f\"Precision: {precision_nb:.4f}\")\n",
    "print(f\"Recall:    {recall_nb:.4f}\")\n",
    "print(f\"F1 Score:  {f1_nb:.4f}\")\n",
    "\n",
    "print(\"\\n\" + classification_report(y_test, y_pred_nb, target_names=['Negative', 'Positive']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
